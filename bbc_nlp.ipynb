{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt - Text Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer # für BoW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # für TF-IDF\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "from save_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Textfiles\n",
    "\n",
    "Datensatz - Kaggle: https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification/code\n",
    "\n",
    "Im Ordner BBC gibt es für jede News Kategorie einen Unterordner in welchen die Artikel gespeichert sind.\n",
    "\n",
    "- business\n",
    "- entertainment\n",
    "- politics\n",
    "- sport\n",
    "- tech\n",
    "\n",
    "Die einzelnen Textfiles beinhalten in der ersten Zeile den Titel und darunter den Inhalt. \n",
    "\n",
    "Für jedes Textfile wird der Titel des Artikels und den Artikel extrahiert und anschliessend in einem Dataframe abgespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./bbc/\"\n",
    "directory = []\n",
    "file = []\n",
    "title = []\n",
    "text = []\n",
    "label = []\n",
    "for root, dir, files in os.walk(path):\n",
    "    try:\n",
    "        files.remove(\"README.TXT\")\n",
    "    except:\n",
    "        pass\n",
    "    for filename in files:\n",
    "        directory.append(root)\n",
    "        file.append(filename)\n",
    "        label.append(root.split(\"/\")[-1])\n",
    "        fullpathfile = os.path.join(root,filename)\n",
    "        with open(fullpathfile,\"r\", encoding = \"utf8\", errors = \"ignore\") as infile:\n",
    "            intext = \"\"\n",
    "            firstline = True\n",
    "            for line in infile:\n",
    "                if firstline:\n",
    "                    title.append(line.replace('\\n',''))\n",
    "                    firstline = False\n",
    "                else:\n",
    "                    intext = intext + \" \" + line.replace('\\n','')\n",
    "            text.append(intext)\n",
    "\n",
    "bbc_df = pd.DataFrame(list(zip(directory,file,title,text,label)),\n",
    "                columns = ['directory', 'file', 'title', 'text', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarn...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yu...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dom...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        directory     file                              title  \\\n",
       "0  ./bbc/business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  ./bbc/business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  ./bbc/business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  ./bbc/business  004.txt  High fuel prices hit BA's profits   \n",
       "4  ./bbc/business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                                text     label  \n",
       "0    Quarterly profits at US media giant TimeWarn...  business  \n",
       "1    The dollar has hit its highest level against...  business  \n",
       "2    The owners of embattled Russian oil giant Yu...  business  \n",
       "3    British Airways has blamed high fuel prices ...  business  \n",
       "4    Shares in UK drinks and food firm Allied Dom...  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anzahl Dokumenten\n",
    "bbc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "directory    0\n",
       "file         0\n",
       "title        0\n",
       "text         0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD STATISCHE ANALYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels --> Numeric\n",
    "\n",
    "Hier werden die Labels in numerische Label umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarn...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yu...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dom...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        directory     file                              title  \\\n",
       "0  ./bbc/business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  ./bbc/business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  ./bbc/business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  ./bbc/business  004.txt  High fuel prices hit BA's profits   \n",
       "4  ./bbc/business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                                text     label  label_num  \n",
       "0    Quarterly profits at US media giant TimeWarn...  business          0  \n",
       "1    The dollar has hit its highest level against...  business          0  \n",
       "2    The owners of embattled Russian oil giant Yu...  business          0  \n",
       "3    British Airways has blamed high fuel prices ...  business          0  \n",
       "4    Shares in UK drinks and food firm Allied Dom...  business          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df['label_num'] = LabelEncoder().fit_transform(bbc_df['label'])\n",
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lookup_table = {0: 'business',\n",
    "                    1: 'entertainment',\n",
    "                    2: 'politics',\n",
    "                    3: 'sport',\n",
    "                    4: 'tech'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "In diesem Teil werden verschiedene Text preprocessing Schritte auf die einzelnen Dokumenten ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    \"\"\"\n",
    "    Alle Wörter im Dokument in lowercase umwandeln\n",
    "    \"\"\"\n",
    "    # Alle Wörter in lowercase umwandeln\n",
    "    res = text.lower()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Die englischen Stoppwörter entfernen\n",
    "    \"\"\"\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    res = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    \"\"\"\n",
    "    Entfernung von Zahlen\n",
    "    \"\"\"\n",
    "    NUMBERS = '[0-9]'\n",
    "    res = re.sub(NUMBERS, '', str(text))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbols(text):\n",
    "    \"\"\"\n",
    "    Entfernung von speziellen characters\n",
    "    \"\"\"\n",
    "    SPECIAL_CHARACTERS = '[^A-Za-z0-9.]+'\n",
    "    res = re.sub(SPECIAL_CHARACTERS, ' ', str(text))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \"\"\"\n",
    "    Entfernung von Punktuation\n",
    "    \"\"\"\n",
    "    PUNCTUATIONS = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in text:\n",
    "        if ele in PUNCTUATIONS:\n",
    "            text = text.replace(ele, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stem(text):\n",
    "    \"\"\"\n",
    "    Andwendung von Porterstemmer\n",
    "\n",
    "    \"\"\"\n",
    "    res = ' '.join(PorterStemmer().stem(word) for word in text.split())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text, pos = False):\n",
    "    \"\"\"\n",
    "    Anwendung von Lemmatisierung\n",
    "\n",
    "    \"\"\"\n",
    "    if pos == True:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        res = ' '.join(lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split())\n",
    "    else:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        res = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(text):\n",
    "    \"\"\"\n",
    "    Entferne Wörter mit länge = 1\n",
    "    \"\"\"\n",
    "    res = ' '.join(word for word in text.split() if len(word)>1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lower = False, stopwords = False, numbers = False, symbols = False, punct = False, char = False, porter_stemmer = False, lemmatizer = False):\n",
    "    \"\"\"\n",
    "    Textbereinigung\n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "        lower (bool, optional): Anwendung von lowercase() Funktion. Defaults to False.\n",
    "        stopwords (bool, optional): Anwendung von remove_stopwords() Funktion. Defaults to False.\n",
    "        numbers (bool, optional): Anwendung von remove_numbers() Funktion. Defaults to False.\n",
    "        symbols (bool, optional): Anwendung von remove_symbols() Funktion. Defaults to False.\n",
    "        punct (bool, optional): Anwendung von remove_punct() Funktion. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: Bereinigter Text\n",
    "    \"\"\"\n",
    "\n",
    "    #----- Text to lowercase\n",
    "    if lower == True:\n",
    "        text = lowercase(text)\n",
    "    # text = text.lower()\n",
    "\n",
    "    #----- Entferne die Stoppwörter\n",
    "    if stopwords == True:\n",
    "        text = remove_stopwords(text)\n",
    "    # text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "\n",
    "    #----- Entferne Zahlen\n",
    "    if numbers == True:\n",
    "        text = remove_numbers(text)\n",
    "    # text = re.sub(NUMBERS, '', text)\n",
    "\n",
    "    #----- Entferne Symbole\n",
    "    if symbols == True:\n",
    "        text = remove_symbols(text)\n",
    "    # text = re.sub(SPECIAL_CHARACTERS, ' ', text)\n",
    "\n",
    "    #----- Entferne Punctuations\n",
    "    if punct == True:\n",
    "        text = remove_punct(text)\n",
    "    # for ele in text:\n",
    "    #     if ele in PUNCTUATIONS:\n",
    "    #         text = text.replace(ele, \"\")\n",
    "\n",
    "    #----- Entferne Wörter mit Länge 1\n",
    "    if char == True:\n",
    "        text = remove_char(text)\n",
    "\n",
    "    #----- Porter Stemmer\n",
    "    if porter_stemmer == True:\n",
    "        text = porter_stem(text)\n",
    "\n",
    "    #----- Lemmatizer\n",
    "    if lemmatizer == True:\n",
    "        text = lemmatization(text, True)\n",
    "\n",
    "   \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning_args = (True, True, True, True, True, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# Anwendung der Textbereinigungs Funktion\n",
    "#--------------------------------------------\n",
    "cleaning_args = (True, True, True, True, True, True, False, False)\n",
    "# cleaning_args = (False, False, False, False, False, False, False, False)\n",
    "bbc_df['text_clean'] = bbc_df['text'].apply(clean_text, args = cleaning_args)\n",
    "\n",
    "# Mit Lemmatisierung\n",
    "# cleaning_args = (True, True, True, True, True, True, False, True)\n",
    "# bbc_df['text_clean'] = bbc_df['text'].apply(clean_text, args = cleaning_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quarterli profit us media giant timewarn jump bn three month decemb year earlier firm one biggest investor googl benefit sale high speed internet connect higher advert sale timewarn said fourth quarter sale rose bn bn profit buoy one off gain offset profit dip warner bro less user aol time warner said friday own search engin googl internet busi aol mix fortun lost subscrib fourth quarter profit lower preced three quarter howev compani said aol underli profit except item rose back stronger internet advertis revenu hope increas subscrib offer onlin servic free timewarn internet custom tri sign aol exist custom high speed broadband timewarn also restat result follow probe us secur exchang commiss sec close conclud time warner fourth quarter profit slightli better analyst expect film divis saw profit slump help box offic flop alexand catwoman sharp contrast year earlier third final film lord ring trilog boost result full year timewarn post profit bn perform revenu grew bn our financi perform strong meet exceed full year object greatli enhanc flexibl chairman chief execut richard parson said timewarn project oper earn growth around also expect higher revenu wider profit margin timewarn restat account part effort resolv inquiri aol us market regul alreadi offer pay settl charg deal review sec compani said unabl estim amount need set asid legal reserv previous set intend adjust way account deal german music publish bertelsmann purchas stake aol europ report advertis revenu book sale stake aol europ loss valu stake'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# Beispiel - Bereinigter Text\n",
    "#--------------------------------------------\n",
    "bbc_df['text_clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaning Schritte in einem Textfile im Ordner Results\n",
    "base_dir = \"./results/\"\n",
    "foldername = \"Full_text_cleaning\"\n",
    "save_cleaning_steps(base_dir, foldername, str(cleaning_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train- & Test-Split\n",
    "\n",
    "Die Daten in Trainings- und Testdaten aufteilen. \n",
    "\n",
    "80% Trainingsdaten und 20% Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bbc_df['text_clean'], bbc_df['label_num'], random_state = 0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variante 1: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_vectorizer(default = True):\n",
    "    #--------------------------------------------\n",
    "    # Mit Default einstellungen\n",
    "    #--------------------------------------------\n",
    "    if default == True:\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        save_count_vectorizer_parameters(base_dir, foldername, 'default Einstellungen')\n",
    "    else:\n",
    "        #--------------------------------------------\n",
    "        # mit definierten Parameter\n",
    "        #--------------------------------------------\n",
    "        ngram_range = (1,1)\n",
    "        max_features = 3000\n",
    "        min_df = 5 # Minimum number of documents that should contain this feature\n",
    "        max_df = 0.7 # Only the words which occur in a maximum of max_df percentage of all the documents. \n",
    "        count_vectorizer = CountVectorizer(ngram_range=ngram_range,max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "        save_count_vectorizer_parameters(base_dir, foldername, ('ngram_range: '+str(ngram_range)+' max_features: '+str(max_features)+' min_df: '+str(min_df)+' max_df: '+str(max_df)))\n",
    "    return count_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = cnt_vectorizer(default = False)\n",
    "# count_vectorizer = cnt_vectorizer(default = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------\n",
    "# # Anzahl Features - X_train\n",
    "# # --------------------------------------------\n",
    "# X_train_bow = count_vectorizer.fit_transform(X_train)\n",
    "# len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation mit CountVectorizer\n",
    "\n",
    "In diesem Abschnitt werden verschiedene Algorithmen ausprobiert und mit Hilfe von Hyperparameter Tuning werden die Parameter optimiert. Mit Cross-Validation wird die performance des Schätzern evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "MultinomialNB()\n",
      "LinearSVC()\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestClassifier(),\n",
    "         MultinomialNB(),\n",
    "         LinearSVC(),\n",
    "         LogisticRegression()]\n",
    "\n",
    "param_grid = [[{'model__n_estimators': [100,200,300]}],\n",
    "            [{'model__alpha': [1.0,2.0,2.5]}],\n",
    "            [{'model__C': [0.5,1.0,2.0], 'model__max_iter': [10000]}],\n",
    "            [{'model__C': [1.0,2.0,2.5], 'model__max_iter': [200]}]]\n",
    "\n",
    "# Default Settings / ohne hyperparameter tuning\n",
    "# param_grid = [[{'model__n_estimators': [100]}],\n",
    "#             [{'model__alpha': [1.0]}],\n",
    "#             [{'model__C': [1.0], 'model__max_iter': [1000]}],\n",
    "#             [{'model__C': [1.0], 'model__max_iter': [100]}]]\n",
    "            \n",
    "CV = 5\n",
    "\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "vectorizer = count_vectorizer\n",
    "\n",
    "entries = []\n",
    "i = 0\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_pipe = Pipeline([('vectorizer', vectorizer), ('model', model)])\n",
    "    clf = GridSearchCV(model_pipe, param_grid[i], scoring='accuracy', cv=CV)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_index = np.where(clf.cv_results_['mean_test_score'] == max(clf.cv_results_['mean_test_score']))\n",
    "    best_param = list(clf.best_params_.keys())\n",
    "    for key in best_param:\n",
    "        new_key = key.split(\"model__\",1)[1]\n",
    "        clf.best_params_[new_key] = clf.best_params_.pop(key)\n",
    "    for fold_idx in range(0,CV):\n",
    "        tag = 'split'+str(fold_idx)+'_test_score'\n",
    "        entries.append((model_name, fold_idx+1, clf.cv_results_[tag][best_index][0], clf.best_params_))\n",
    "    i += 1\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy', 'best params']) \n",
    "\n",
    "save_count_vectorizer_CV_results(base_dir, foldername, str(models), str(param_grid), cv_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974719</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.963483</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974719</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.980337</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960674</td>\n",
       "      <td>{'C': 2.0, 'max_iter': 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>{'C': 2.0, 'max_iter': 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>{'C': 2.0, 'max_iter': 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963483</td>\n",
       "      <td>{'C': 2.0, 'max_iter': 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>{'C': 2.0, 'max_iter': 10000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963483</td>\n",
       "      <td>{'C': 2.5, 'max_iter': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.980337</td>\n",
       "      <td>{'C': 2.5, 'max_iter': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>{'C': 2.5, 'max_iter': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974719</td>\n",
       "      <td>{'C': 2.5, 'max_iter': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>{'C': 2.5, 'max_iter': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  fold_idx  accuracy                    best params\n",
       "0   RandomForestClassifier         1  0.966292          {'n_estimators': 300}\n",
       "1   RandomForestClassifier         2  0.966292          {'n_estimators': 300}\n",
       "2   RandomForestClassifier         3  0.971910          {'n_estimators': 300}\n",
       "3   RandomForestClassifier         4  0.969101          {'n_estimators': 300}\n",
       "4   RandomForestClassifier         5  0.971910          {'n_estimators': 300}\n",
       "5            MultinomialNB         1  0.974719                 {'alpha': 2.0}\n",
       "6            MultinomialNB         2  0.963483                 {'alpha': 2.0}\n",
       "7            MultinomialNB         3  0.974719                 {'alpha': 2.0}\n",
       "8            MultinomialNB         4  0.966292                 {'alpha': 2.0}\n",
       "9            MultinomialNB         5  0.980337                 {'alpha': 2.0}\n",
       "10               LinearSVC         1  0.960674  {'C': 2.0, 'max_iter': 10000}\n",
       "11               LinearSVC         2  0.977528  {'C': 2.0, 'max_iter': 10000}\n",
       "12               LinearSVC         3  0.966292  {'C': 2.0, 'max_iter': 10000}\n",
       "13               LinearSVC         4  0.963483  {'C': 2.0, 'max_iter': 10000}\n",
       "14               LinearSVC         5  0.971910  {'C': 2.0, 'max_iter': 10000}\n",
       "15      LogisticRegression         1  0.963483    {'C': 2.5, 'max_iter': 200}\n",
       "16      LogisticRegression         2  0.980337    {'C': 2.5, 'max_iter': 200}\n",
       "17      LogisticRegression         3  0.966292    {'C': 2.5, 'max_iter': 200}\n",
       "18      LogisticRegression         4  0.974719    {'C': 2.5, 'max_iter': 200}\n",
       "19      LogisticRegression         5  0.977528    {'C': 2.5, 'max_iter': 200}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "g = sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "None\n",
    "plt.savefig(base_dir+foldername+\"/model_cv_boxplot.png\", facecolor = 'white', transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.967978\n",
       "LogisticRegression        0.972472\n",
       "MultinomialNB             0.971910\n",
       "RandomForestClassifier    0.969101\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersage - Testset\n",
    "\n",
    "Hier wird mit dem besten Model einer vorhersage auf den Testdaten gemacht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(cv_df, X_train, y_train, y_test, vectorizer, filename):\n",
    "    model_name = cv_df.model_name.unique()\n",
    "    for model in model_name:\n",
    "        if model == 'LinearSVC':\n",
    "            estimator = LinearSVC(C = cv_df[cv_df['model_name'] == 'LinearSVC'].reset_index()['best params'][0].get('C'), max_iter = cv_df[cv_df['model_name'] == 'LinearSVC'].reset_index()['best params'][0].get('max_iter'))\n",
    "            model_pipeline = make_pipeline(vectorizer, estimator)\n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            y_pred = model_pipeline.predict(X_test)\n",
    "            conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "            report = classification_report(y_test,y_pred, digits = 4)\n",
    "            save_test_prediction(base_dir, foldername, filename, str(model), str(conf_matrix), str(report))\n",
    "            save_test_pred_labels(y_test, y_pred, base_dir, foldername,'/LinearSVC_pred_labels')\n",
    "            if vectorizer == count_vectorizer:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/LinearSVC_wrong_pred')\n",
    "            else:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/LinearSVC_wrong_pred_TFIDF')\n",
    "        elif model == 'LogisticRegression':\n",
    "            estimator = LogisticRegression(C = cv_df[cv_df['model_name'] == 'LogisticRegression'].reset_index()['best params'][0].get('C'), max_iter = cv_df[cv_df['model_name'] == 'LogisticRegression'].reset_index()['best params'][0].get('max_iter'))\n",
    "            model_pipeline = make_pipeline(vectorizer, estimator)\n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            y_pred = model_pipeline.predict(X_test)\n",
    "            conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "            report = classification_report(y_test,y_pred, digits = 4)\n",
    "            save_test_prediction(base_dir, foldername, filename, str(model), str(conf_matrix), str(report))\n",
    "            save_test_pred_labels(y_test, y_pred, base_dir, foldername,'/LogisicRegression_pred_labels')\n",
    "            if vectorizer == count_vectorizer:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/LogisicRegression_wrong_pred')\n",
    "            else:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/LogisicRegression_wrong_pred_TFIDF')\n",
    "        elif model == 'MultinomialNB':\n",
    "            estimator = MultinomialNB(alpha = cv_df[cv_df['model_name'] == 'MultinomialNB'].reset_index()['best params'][0].get('alpha'))\n",
    "            model_pipeline = make_pipeline(vectorizer, estimator)\n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            y_pred = model_pipeline.predict(X_test)\n",
    "            conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "            report = classification_report(y_test,y_pred, digits = 4)\n",
    "            save_test_prediction(base_dir, foldername, filename, str(model), str(conf_matrix), str(report))\n",
    "            save_test_pred_labels(y_test, y_pred, base_dir, foldername,'/MultinomialNB_pred_labels')\n",
    "            if vectorizer == count_vectorizer:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/MultinomialNB_wrong_pred')\n",
    "            else:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/MultinomialNB_wrong_pred_TFIDF')\n",
    "        elif model == 'RandomForestClassifier':\n",
    "            estimator = RandomForestClassifier(n_estimators=cv_df[cv_df['model_name'] == 'RandomForestClassifier'].reset_index()['best params'][0].get('n_estimators'))\n",
    "            model_pipeline = make_pipeline(vectorizer, estimator)\n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            y_pred = model_pipeline.predict(X_test)\n",
    "            conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "            report = classification_report(y_test,y_pred, digits = 4)\n",
    "            save_test_prediction(base_dir, foldername, filename, str(model), str(conf_matrix), str(report))\n",
    "            save_test_pred_labels(y_test, y_pred, base_dir, foldername,'/RandomForest_pred_labels')\n",
    "            if vectorizer == count_vectorizer:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/RandomForest_wrong_pred')\n",
    "            else:\n",
    "                save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/RandomForest_wrong_pred_TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(cv_df, X_train, y_train, y_test, count_vectorizer, filename = '/test_prediction_count_vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorhersage mit VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_voting_classifier(cv_df, X_train, y_train, y_test, vectorizer, filename):\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    model_name = cv_df.model_name.unique()\n",
    "    estimators = []\n",
    "    for model in model_name:\n",
    "        if model == 'LinearSVC':\n",
    "            estimator = LinearSVC(C = cv_df[cv_df['model_name'] == 'LinearSVC'].reset_index()['best params'][0].get('C'), max_iter = cv_df[cv_df['model_name'] == 'LinearSVC'].reset_index()['best params'][0].get('max_iter'))\n",
    "            estimators.append((\"p1\", make_pipeline(vectorizer, CalibratedClassifierCV(estimator))))\n",
    "        elif model == 'LogisticRegression':\n",
    "            estimator = LogisticRegression(C = cv_df[cv_df['model_name'] == 'LogisticRegression'].reset_index()['best params'][0].get('C'), max_iter = cv_df[cv_df['model_name'] == 'LogisticRegression'].reset_index()['best params'][0].get('max_iter'))\n",
    "            estimators.append((\"p2\", make_pipeline(vectorizer, estimator)))\n",
    "        elif model == 'MultinomialNB':\n",
    "            estimator = MultinomialNB(alpha = cv_df[cv_df['model_name'] == 'MultinomialNB'].reset_index()['best params'][0].get('alpha'))\n",
    "            estimators.append((\"p3\", make_pipeline(vectorizer, estimator)))\n",
    "        elif model == 'RandomForestClassifier':\n",
    "            estimator = RandomForestClassifier(n_estimators=cv_df[cv_df['model_name'] == 'RandomForestClassifier'].reset_index()['best params'][0].get('n_estimators'))\n",
    "            estimators.append((\"p4\", make_pipeline(vectorizer, estimator)))\n",
    "    p5 = make_pipeline(VotingClassifier(estimators=estimators, voting='soft'))\n",
    "    p5.fit(X_train, y_train)\n",
    "    y_pred = p5.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    report = classification_report(y_test,y_pred, digits = 4)\n",
    "    save_test_prediction(base_dir, foldername, filename, 'Voting Classifier', str(conf_matrix), str(report))\n",
    "    save_test_pred_labels(y_test, y_pred, base_dir, foldername,'/VotingClassifier_pred_labels')\n",
    "    if vectorizer == count_vectorizer:\n",
    "        save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/VotingClassifier_wrong_pred')\n",
    "    else:\n",
    "        save_wrong_predictions(y_test, y_pred, base_dir, foldername, '/VotingClassifier_wrong_pred_TFIDF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_voting_classifier(cv_df, X_train, y_train, y_test, count_vectorizer, filename = '/test_prediction_count_vectorizer_voting_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variante 2: TF-IDF\n",
    "\n",
    "funktion einstellungen ausprobieren, ngrams, usw..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(default = True):\n",
    "    #--------------------------------------------\n",
    "    # Mit Default einstellungen\n",
    "    #--------------------------------------------\n",
    "    if default == True:\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        save_tfidf_vectorizer_parameters(base_dir, foldername, 'default Einstellungen')\n",
    "    else:\n",
    "        #--------------------------------------------\n",
    "        # mit definierten Parameter\n",
    "        #--------------------------------------------\n",
    "        ngram_range = (1,1)\n",
    "        max_features = 3000\n",
    "        min_df = 5 # Minimum number of documents that should contain this feature\n",
    "        max_df = 0.7 # Only the words which occur in a maximum of max_df percentage of all the documents. \n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range,max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "        save_tfidf_vectorizer_parameters(base_dir, foldername, ('ngram_range: '+str(ngram_range)+' max_features: '+str(max_features)+' min_df: '+str(min_df)+' max_df: '+str(max_df)))\n",
    "    return tfidf_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_vectorizer = tfidf_vectorizer(default = False)\n",
    "# TFIDF_vectorizer = tfidf_vectorizer(default = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation mit TF-IDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "MultinomialNB()\n",
      "LinearSVC()\n",
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestClassifier(),\n",
    "         MultinomialNB(),\n",
    "         LinearSVC(),\n",
    "         LogisticRegression()]\n",
    "\n",
    "param_grid = [[{'model__n_estimators': [100,200,300]}],\n",
    "            [{'model__alpha': [1.0,2.0,2.5]}],\n",
    "            [{'model__C': [0.5,1.0,2.0], 'model__max_iter': [10000]}],\n",
    "            [{'model__C': [1.0,2.0,2.5], 'model__max_iter': [200]}]]\n",
    "\n",
    "# Default Settings / ohne hyperparameter tuning\n",
    "# param_grid = [[{'model__n_estimators': [100]}],\n",
    "#             [{'model__alpha': [1.0]}],\n",
    "#             [{'model__C': [1.0], 'model__max_iter': [1000]}],\n",
    "#             [{'model__C': [1.0], 'model__max_iter': [100]}]]\n",
    "\n",
    "CV = 5\n",
    "\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "vectorizer = TFIDF_vectorizer\n",
    "\n",
    "entries = []\n",
    "i = 0\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_pipe = Pipeline([('vectorizer', vectorizer), ('model', model)])\n",
    "    clf = GridSearchCV(model_pipe, param_grid[i], scoring='accuracy', cv=CV)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_index = np.where(clf.cv_results_['mean_test_score'] == max(clf.cv_results_['mean_test_score']))\n",
    "    best_param = list(clf.best_params_.keys())\n",
    "    for key in best_param:\n",
    "        new_key = key.split(\"model__\",1)[1]\n",
    "        clf.best_params_[new_key] = clf.best_params_.pop(key)\n",
    "    for fold_idx in range(0,CV):\n",
    "        tag = 'split'+str(fold_idx)+'_test_score'\n",
    "        entries.append((model_name, fold_idx+1, clf.cv_results_[tag][best_index][0], clf.best_params_))\n",
    "    i += 1\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy', 'best params']) \n",
    "\n",
    "save_tfidf_vectorizer_CV_results(base_dir, foldername, str(models), str(param_grid), cv_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "g = sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "None\n",
    "plt.savefig(base_dir+foldername+\"/model_tfidf_cv_boxplot.png\", facecolor = 'white', transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.977528\n",
       "LogisticRegression        0.977528\n",
       "MultinomialNB             0.970787\n",
       "RandomForestClassifier    0.966854\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersage - Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(cv_df, X_train, y_train, y_test, TFIDF_vectorizer, filename = '/test_prediction_tfidf_vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorhersage mit VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_voting_classifier(cv_df, X_train, y_train, y_test, TFIDF_vectorizer, filename = '/test_prediction_tfidf_vectorizer_voting_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falsch Vorhersagen\n",
    "\n",
    "In diesem Abschnitt wird untersucht welche Artikel in allen Schätzer falsch vorhergesagt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparelists(a,b,c,d):\n",
    "    z = [x for x in b\n",
    "         if x in a and x in c and x in d] #list comprehension\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[503, 971, 722, 1436, 254, 486]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = pd.read_pickle(base_dir + foldername + \"/LinearSVC_wrong_pred_TFIDF.pickle\") \n",
    "list2 = pd.read_pickle(base_dir + foldername + \"/RandomForest_wrong_pred_TFIDF.pickle\") \n",
    "list3 = pd.read_pickle(base_dir + foldername + \"/LogisicRegression_wrong_pred_TFIDF.pickle\") \n",
    "list4 = pd.read_pickle(base_dir + foldername + \"/MultinomialNB_wrong_pred_TFIDF.pickle\") \n",
    "wrong_pred_list = comparelists(list1,list2,list3, list4)\n",
    "wrong_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>504.txt</td>\n",
       "      <td>Aids and climate top Davos agenda</td>\n",
       "      <td>Climate change and the fight against Aids ar...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>climat chang fight aid lead list concern first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          directory     file                              title  \\\n",
       "503  ./bbc/business  504.txt  Aids and climate top Davos agenda   \n",
       "\n",
       "                                                  text     label  label_num  \\\n",
       "503    Climate change and the fight against Aids ar...  business          0   \n",
       "\n",
       "                                            text_clean  \n",
       "503  climat chang fight aid lead list concern first...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[wrong_pred_list[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Climate change and the fight against Aids are leading the list of concerns for the first day of the World Economic Forum in the Swiss resort of Davos.  Some 2,000 business and political leaders from around the globe will listen to UK Prime Minister Tony Blair\\'s opening speech on Wednesday. Mr Blair will focus on Africa\\'s development plans and global warming. Earlier in the day came an update on efforts to have 3 million people on anti-Aids drugs by the end of 2005. The World Health Organisation (WHO) said 700,000 people in poor countries were on life-extending drugs - up from 440,000 six months earlier but amounting to only 12% of the 5.8 million who needed them. A $2bn \"funding gap\" still stood in the way of hitting the 2005 target, the WHO said.  The themes to be stressed by Mr Blair - whose attendance was announced at the last minute - are those he wants to dominate the UK\\'s chairmanship of the G8 group of industrialised states. Other issues to be discussed at the five-day conference range from China\\'s  economic power to Iraq\\'s future after this Sunday\\'s elections. Aside from Mr Blair, more than 20 other world leaders are expected to attend including French President Jacques Chirac - due to speak by video link after bad weather delayed his helicopter - and South African President Thabo Mbeki, whose arrival has been delayed by Ivory Coast peace talks. The Ukraine\\'s new president, Viktor Yushchenko, will also be there - as will newly elected Palestinian leader Mahmoud Abbas. Showbiz figures will also put in an appearance, from U2 frontman Bono - a well-known campaigner on trade and development issues - to Angelina Jolie, a goodwill campaigner for the UN on refugees.  Unlike previous years, protests against the WEF are expected to be muted. Anti-globalisation campaigners have called off a demonstration planned for the weekend. At the same time, about 100,000 people are expected to converge on the Brazilian resort of Porto Alegre for the World Social Forum - the so-called \"anti-Davos\" for campaigners against globalisation, for fair trade, and many other causes.  In contrast, the Davos forum is dominated by business issues - from outsourcing to corporate leadership - with bosses of more than a fifth of the world\\'s 500 largest companies scheduled to attend. A survey published on the eve of the conference by PricewaterhouseCoopers said four in ten business leaders were \"very confident\" that their companies would see sales rise in 2005. Asian and American executives, however, were much more confident than their European counterparts. But the political discussions, focusing on Iran, Iraq and China, are likely to dominate media attention.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[wrong_pred_list[0]]]['text'][wrong_pred_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'climat chang fight aid lead list concern first day world econom forum swiss resort davo busi polit leader around globe listen uk prime minist toni blair open speech wednesday mr blair focu africa develop plan global warm earlier day came updat effort million peopl anti aid drug end world health organis who said peopl poor countri life extend drug six month earlier amount million need them bn fund gap still stood way hit target said theme stress mr blair whose attend announc last minut want domin uk chairmanship group industrialis state issu discuss five day confer rang china econom power iraq futur sunday elect asid mr blair world leader expect attend includ french presid jacqu chirac due speak video link bad weather delay helicopt south african presid thabo mbeki whose arriv delay ivori coast peac talk ukrain new presid viktor yushchenko also newli elect palestinian leader mahmoud abba showbiz figur also put appear frontman bono well known campaign trade develop issu angelina joli goodwil campaign un refuge unlik previou year protest wef expect mute anti globalis campaign call demonstr plan weekend time peopl expect converg brazilian resort porto alegr world social forum so call anti davo campaign globalis fair trade mani caus contrast davo forum domin busi issu outsourc corpor leadership boss fifth world largest compani schedul attend survey publish eve confer pricewaterhousecoop said four ten busi leader veri confid compani would see sale rise asian american execut howev much confid european counterpart polit discuss focus iran iraq china like domin media attent'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[wrong_pred_list[0]]]['text_clean'][wrong_pred_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(index):\n",
    "    list1 = pd.read_pickle(base_dir + foldername + \"/LinearSVC_pred_labels.pickle\") \n",
    "    list2 = pd.read_pickle(base_dir + foldername + \"/RandomForest_pred_labels.pickle\") \n",
    "    list3 = pd.read_pickle(base_dir + foldername + \"/LogisicRegression_pred_labels.pickle\") \n",
    "    list4 = pd.read_pickle(base_dir + foldername + \"/MultinomialNB_pred_labels.pickle\") \n",
    "    print('True Value: ' + bbc_df.iloc[[wrong_pred_list[0]]]['label'])\n",
    "    return [('LinearSVC','Preditcted: ' + label_lookup_table[list1.loc[[index]][0][index]]), ('RandomForest','Preditcted: ' +  label_lookup_table[list2.loc[[index]][0][index]]), ('LogisticRegression','Preditcted: ' +  label_lookup_table[list3.loc[[index]][0][index]]), ('MultinomialNB','Preditcted: ' +  label_lookup_table[list4.loc[[index]][0][index]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503    True Value: business\n",
      "Name: label, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LinearSVC', 'Preditcted: politics'),\n",
       " ('RandomForest', 'Preditcted: politics'),\n",
       " ('LogisticRegression', 'Preditcted: politics'),\n",
       " ('MultinomialNB', 'Preditcted: politics')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels(index = wrong_pred_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lade vordefinierten Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a simple Feed-Forward layer over averaged pre-trained word embeddings\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier werden die Originale Dokumenten verwendet\n",
    "X_train_bbc, X_test_bbc, y_train_bbc, y_test_bbc = train_test_split(bbc_df['text'], bbc_df['label'], random_state = 0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Download the embeddings and vocab file here: https://drive.switch.ch/index.php/s/rNmy0yKDDkRAmcq\n",
    "word_embeddings = np.load('wiki.multi.en.vec_data.npy')\n",
    "vocab = json.load(open('wiki.multi.en.vec_vocab.json'))\n",
    "\n",
    "def tokenize(texts):\n",
    "    return [re.findall(r'\\w+', text.lower()) for text in texts]\n",
    "\n",
    "train_tokens = tokenize(X_train_bbc.tolist())\n",
    "train_tokens_clean = tokenize(X_train.tolist())\n",
    "ohe = OneHotEncoder(sparse=False)  # One-hot encode string labels\n",
    "train_labels = ohe.fit_transform([[label] for label in y_train_bbc.tolist()])\n",
    "train_labels_clean = ohe.fit_transform([[label] for label in y_train.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0112864 , -0.00206967, -0.0515041 , ...,  0.0435525 ,\n",
       "        -0.00774608,  0.0724234 ],\n",
       "       [-0.0469256 , -0.00058526, -0.0750844 , ...,  0.0267626 ,\n",
       "        -0.0513555 ,  0.0166127 ],\n",
       "       [-0.0324474 , -0.0462027 , -0.00872643, ...,  0.0826505 ,\n",
       "        -0.0649553 ,  0.0175795 ],\n",
       "       ...,\n",
       "       [-0.0119003 , -0.0123243 , -0.065963  , ...,  0.0184328 ,\n",
       "        -0.0295059 , -0.0160871 ],\n",
       "       [-0.01293725, -0.00830302, -0.04299837, ...,  0.04162215,\n",
       "         0.02835915,  0.0066784 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " '.': 1,\n",
       " 'the': 2,\n",
       " '</s>': 3,\n",
       " 'of': 4,\n",
       " '-': 5,\n",
       " 'in': 6,\n",
       " 'and': 7,\n",
       " \"'\": 8,\n",
       " ')': 9,\n",
       " '(': 10,\n",
       " 'to': 11,\n",
       " 'a': 12,\n",
       " 'is': 13,\n",
       " 'was': 14,\n",
       " 'on': 15,\n",
       " 's': 16,\n",
       " 'for': 17,\n",
       " 'as': 18,\n",
       " 'by': 19,\n",
       " 'that': 20,\n",
       " 'it': 21,\n",
       " 'with': 22,\n",
       " 'from': 23,\n",
       " 'at': 24,\n",
       " 'he': 25,\n",
       " 'this': 26,\n",
       " 'be': 27,\n",
       " 'i': 28,\n",
       " 'an': 29,\n",
       " 'utc': 30,\n",
       " 'his': 31,\n",
       " 'not': 32,\n",
       " '–': 33,\n",
       " 'are': 34,\n",
       " 'or': 35,\n",
       " 'talk': 36,\n",
       " 'which': 37,\n",
       " 'also': 38,\n",
       " 'has': 39,\n",
       " 'were': 40,\n",
       " 'but': 41,\n",
       " 'have': 42,\n",
       " '#': 43,\n",
       " 'one': 44,\n",
       " 'rd': 45,\n",
       " 'new': 46,\n",
       " 'first': 47,\n",
       " 'page': 48,\n",
       " 'no': 49,\n",
       " 'you': 50,\n",
       " 'they': 51,\n",
       " 'had': 52,\n",
       " 'article': 53,\n",
       " 't': 54,\n",
       " 'who': 55,\n",
       " '?': 56,\n",
       " 'all': 57,\n",
       " 'their': 58,\n",
       " 'there': 59,\n",
       " 'been': 60,\n",
       " 'made': 61,\n",
       " 'its': 62,\n",
       " 'people': 63,\n",
       " 'may': 64,\n",
       " 'after': 65,\n",
       " '%': 66,\n",
       " 'other': 67,\n",
       " 'should': 68,\n",
       " 'two': 69,\n",
       " 'score': 70,\n",
       " 'her': 71,\n",
       " 'can': 72,\n",
       " 'would': 73,\n",
       " 'more': 74,\n",
       " 'if': 75,\n",
       " 'she': 76,\n",
       " 'about': 77,\n",
       " 'when': 78,\n",
       " 'time': 79,\n",
       " 'team': 80,\n",
       " 'american': 81,\n",
       " 'such': 82,\n",
       " 'th': 83,\n",
       " 'do': 84,\n",
       " 'discussion': 85,\n",
       " 'links': 86,\n",
       " 'only': 87,\n",
       " 'some': 88,\n",
       " 'up': 89,\n",
       " 'see': 90,\n",
       " 'united': 91,\n",
       " 'years': 92,\n",
       " 'into': 93,\n",
       " '/': 94,\n",
       " 'school': 95,\n",
       " 'so': 96,\n",
       " 'world': 97,\n",
       " 'university': 98,\n",
       " 'during': 99,\n",
       " 'out': 100,\n",
       " 'state': 101,\n",
       " 'states': 102,\n",
       " 'national': 103,\n",
       " 'wikipedia': 104,\n",
       " 'year': 105,\n",
       " 'most': 106,\n",
       " 'city': 107,\n",
       " 'over': 108,\n",
       " 'used': 109,\n",
       " 'then': 110,\n",
       " 'd': 111,\n",
       " 'than': 112,\n",
       " 'county': 113,\n",
       " 'external': 114,\n",
       " 'm': 115,\n",
       " 'where': 116,\n",
       " 'will': 117,\n",
       " 'de': 118,\n",
       " 'what': 119,\n",
       " 'delete': 120,\n",
       " 'any': 121,\n",
       " 'these': 122,\n",
       " 'january': 123,\n",
       " 'march': 124,\n",
       " 'august': 125,\n",
       " 'july': 126,\n",
       " 'being': 127,\n",
       " 'film': 128,\n",
       " 'him': 129,\n",
       " 'many': 130,\n",
       " 'south': 131,\n",
       " 'september': 132,\n",
       " 'like': 133,\n",
       " 'between': 134,\n",
       " 'october': 135,\n",
       " 'three': 136,\n",
       " 'june': 137,\n",
       " 'well': 138,\n",
       " 'use': 139,\n",
       " 'war': 140,\n",
       " 'under': 141,\n",
       " 'them': 142,\n",
       " 'april': 143,\n",
       " 'we': 144,\n",
       " 'born': 145,\n",
       " 'december': 146,\n",
       " 'link': 147,\n",
       " 'while': 148,\n",
       " 'c': 149,\n",
       " 'later': 150,\n",
       " 'part': 151,\n",
       " 'november': 152,\n",
       " 'further': 153,\n",
       " 'players': 154,\n",
       " 'list': 155,\n",
       " 'please': 156,\n",
       " 'following': 157,\n",
       " 'my': 158,\n",
       " 'february': 159,\n",
       " 'known': 160,\n",
       " 'second': 161,\n",
       " 'u': 162,\n",
       " 'name': 163,\n",
       " 'group': 164,\n",
       " 'history': 165,\n",
       " 'series': 166,\n",
       " 'just': 167,\n",
       " 'e': 168,\n",
       " 'north': 169,\n",
       " 'work': 170,\n",
       " 'before': 171,\n",
       " 'since': 172,\n",
       " 'season': 173,\n",
       " 'both': 174,\n",
       " 'high': 175,\n",
       " 'st': 176,\n",
       " 'through': 177,\n",
       " 'district': 178,\n",
       " 'now': 179,\n",
       " '!': 180,\n",
       " 'comments': 181,\n",
       " 'because': 182,\n",
       " 'football': 183,\n",
       " 'music': 184,\n",
       " 'however': 185,\n",
       " 'diff': 186,\n",
       " 'century': 187,\n",
       " 'league': 188,\n",
       " 'edits': 189,\n",
       " 'debate': 190,\n",
       " 'title': 191,\n",
       " 'articles': 192,\n",
       " 'john': 193,\n",
       " 'same': 194,\n",
       " 'including': 195,\n",
       " 'could': 196,\n",
       " 'english': 197,\n",
       " 'album': 198,\n",
       " 'number': 199,\n",
       " 'against': 200,\n",
       " 'family': 201,\n",
       " 'user': 202,\n",
       " 'based': 203,\n",
       " 'area': 204,\n",
       " 'became': 205,\n",
       " 'york': 206,\n",
       " 'b': 207,\n",
       " 'life': 208,\n",
       " 'me': 209,\n",
       " 'british': 210,\n",
       " 'international': 211,\n",
       " 'game': 212,\n",
       " '\"': 213,\n",
       " 'above': 214,\n",
       " 'club': 215,\n",
       " 'your': 216,\n",
       " 'until': 217,\n",
       " 'early': 218,\n",
       " 'best': 219,\n",
       " 'west': 220,\n",
       " 'house': 221,\n",
       " 'company': 222,\n",
       " 'general': 223,\n",
       " 'left': 224,\n",
       " 'very': 225,\n",
       " 'here': 226,\n",
       " 'don': 227,\n",
       " 'living': 228,\n",
       " 'day': 229,\n",
       " 'several': 230,\n",
       " 'place': 231,\n",
       " 'party': 232,\n",
       " 'college': 233,\n",
       " 'result': 234,\n",
       " 'keep': 235,\n",
       " 'appropriate': 236,\n",
       " 'four': 237,\n",
       " 'subsequent': 238,\n",
       " 'even': 239,\n",
       " 'class': 240,\n",
       " 'government': 241,\n",
       " 'how': 242,\n",
       " 'called': 243,\n",
       " 'did': 244,\n",
       " 'each': 245,\n",
       " 'found': 246,\n",
       " 'center': 247,\n",
       " 'per': 248,\n",
       " 'style': 249,\n",
       " 'com': 250,\n",
       " 'long': 251,\n",
       " 'country': 252,\n",
       " 'back': 253,\n",
       " 'way': 254,\n",
       " 'does': 255,\n",
       " 'www': 256,\n",
       " 'modify': 257,\n",
       " 'end': 258,\n",
       " 'make': 259,\n",
       " 'public': 260,\n",
       " 'played': 261,\n",
       " 'p': 262,\n",
       " 'won': 263,\n",
       " 'another': 264,\n",
       " 'released': 265,\n",
       " 'added': 266,\n",
       " 'f': 267,\n",
       " 'support': 268,\n",
       " 'games': 269,\n",
       " 'former': 270,\n",
       " 'those': 271,\n",
       " 'films': 272,\n",
       " 'church': 273,\n",
       " 'east': 274,\n",
       " 'line': 275,\n",
       " 'major': 276,\n",
       " 'members': 277,\n",
       " 'good': 278,\n",
       " 'much': 279,\n",
       " 'image': 280,\n",
       " 'show': 281,\n",
       " 'still': 282,\n",
       " 'think': 283,\n",
       " 'below': 284,\n",
       " 'town': 285,\n",
       " 'last': 286,\n",
       " 'system': 287,\n",
       " 'right': 288,\n",
       " 'song': 289,\n",
       " 'non': 290,\n",
       " 'notable': 291,\n",
       " 'section': 292,\n",
       " 'single': 293,\n",
       " 'included': 294,\n",
       " 'align': 295,\n",
       " 'home': 296,\n",
       " 'women': 297,\n",
       " 'television': 298,\n",
       " '—': 299,\n",
       " 'seed': 300,\n",
       " 'member': 301,\n",
       " 'goals': 302,\n",
       " 'sources': 303,\n",
       " '}}': 304,\n",
       " 'book': 305,\n",
       " 'station': 306,\n",
       " 'order': 307,\n",
       " 'old': 308,\n",
       " 'information': 309,\n",
       " 'set': 310,\n",
       " 'own': 311,\n",
       " 'text': 312,\n",
       " 'band': 313,\n",
       " 'point': 314,\n",
       " 'local': 315,\n",
       " 'around': 316,\n",
       " 'river': 317,\n",
       " 'top': 318,\n",
       " 'main': 319,\n",
       " 'language': 320,\n",
       " 'french': 321,\n",
       " 'https': 322,\n",
       " 'named': 323,\n",
       " 'off': 324,\n",
       " 'us': 325,\n",
       " 'note': 326,\n",
       " 'career': 327,\n",
       " 'original': 328,\n",
       " 'age': 329,\n",
       " 'service': 330,\n",
       " 'established': 331,\n",
       " 'located': 332,\n",
       " 're': 333,\n",
       " 'said': 334,\n",
       " 'website': 335,\n",
       " 'population': 336,\n",
       " 'air': 337,\n",
       " 'german': 338,\n",
       " 'law': 339,\n",
       " 'military': 340,\n",
       " '}': 341,\n",
       " 'great': 342,\n",
       " 'ii': 343,\n",
       " 'within': 344,\n",
       " 'clubs': 345,\n",
       " 'published': 346,\n",
       " 'president': 347,\n",
       " 'park': 348,\n",
       " 'official': 349,\n",
       " '$': 350,\n",
       " 'r': 351,\n",
       " 'case': 352,\n",
       " '>': 353,\n",
       " 'london': 354,\n",
       " 'times': 355,\n",
       " 'although': 356,\n",
       " 'small': 357,\n",
       " 'third': 358,\n",
       " 'different': 359,\n",
       " 'due': 360,\n",
       " 'get': 361,\n",
       " 'village': 362,\n",
       " 'closed': 363,\n",
       " 'g': 364,\n",
       " 'art': 365,\n",
       " 'player': 366,\n",
       " 'final': 367,\n",
       " 'l': 368,\n",
       " 'community': 369,\n",
       " 'held': 370,\n",
       " 'n': 371,\n",
       " 'again': 372,\n",
       " 'began': 373,\n",
       " 'army': 374,\n",
       " 'award': 375,\n",
       " 'without': 376,\n",
       " 'death': 377,\n",
       " 'built': 378,\n",
       " 'men': 379,\n",
       " 'large': 380,\n",
       " 'site': 381,\n",
       " '+': 382,\n",
       " 'using': 383,\n",
       " 'deletion': 384,\n",
       " 'white': 385,\n",
       " 'along': 386,\n",
       " 'five': 387,\n",
       " 'central': 388,\n",
       " 'road': 389,\n",
       " 'children': 390,\n",
       " 'free': 391,\n",
       " 'took': 392,\n",
       " 'england': 393,\n",
       " 'include': 394,\n",
       " 'association': 395,\n",
       " 'down': 396,\n",
       " 'j': 397,\n",
       " 'given': 398,\n",
       " 'source': 399,\n",
       " 'x': 400,\n",
       " 'california': 401,\n",
       " 'man': 402,\n",
       " 'version': 403,\n",
       " 'written': 404,\n",
       " 'created': 405,\n",
       " 'media': 406,\n",
       " 'black': 407,\n",
       " 'though': 408,\n",
       " 'php': 409,\n",
       " 'report': 410,\n",
       " 'building': 411,\n",
       " 'la': 412,\n",
       " 'take': 413,\n",
       " 'division': 414,\n",
       " 'comment': 415,\n",
       " 'having': 416,\n",
       " 'king': 417,\n",
       " 'edit': 418,\n",
       " 'stadium': 419,\n",
       " 'died': 420,\n",
       " 'ship': 421,\n",
       " 'research': 422,\n",
       " 'record': 423,\n",
       " 'archive': 424,\n",
       " 'places': 425,\n",
       " 'undo': 426,\n",
       " 'cup': 427,\n",
       " 'records': 428,\n",
       " 'often': 429,\n",
       " 'few': 430,\n",
       " 'received': 431,\n",
       " 'side': 432,\n",
       " 'power': 433,\n",
       " 'education': 434,\n",
       " 'know': 435,\n",
       " 'category': 436,\n",
       " 'water': 437,\n",
       " 'political': 438,\n",
       " 'species': 439,\n",
       " 'field': 440,\n",
       " 'near': 441,\n",
       " '&': 442,\n",
       " 'co': 443,\n",
       " 'australia': 444,\n",
       " 'video': 445,\n",
       " 'need': 446,\n",
       " 'go': 447,\n",
       " 'island': 448,\n",
       " 'form': 449,\n",
       " 'find': 450,\n",
       " 'served': 451,\n",
       " 'play': 452,\n",
       " 'project': 453,\n",
       " 'o': 454,\n",
       " 'according': 455,\n",
       " '//en': 456,\n",
       " 'radio': 457,\n",
       " 'am': 458,\n",
       " 'works': 459,\n",
       " 'proposed': 460,\n",
       " 'every': 461,\n",
       " 'development': 462,\n",
       " 'example': 463,\n",
       " 'live': 464,\n",
       " 'union': 465,\n",
       " 'india': 466,\n",
       " 'next': 467,\n",
       " 'special': 468,\n",
       " 'court': 469,\n",
       " 'region': 470,\n",
       " 'h': 471,\n",
       " 'little': 472,\n",
       " 'short': 473,\n",
       " 'v': 474,\n",
       " 'william': 475,\n",
       " 'province': 476,\n",
       " 'western': 477,\n",
       " 'son': 478,\n",
       " 'france': 479,\n",
       " 'council': 480,\n",
       " 'others': 481,\n",
       " 'royal': 482,\n",
       " 'current': 483,\n",
       " 'street': 484,\n",
       " 'full': 485,\n",
       " 'red': 486,\n",
       " 'too': 487,\n",
       " 'department': 488,\n",
       " 'w': 489,\n",
       " 'san': 490,\n",
       " 'help': 491,\n",
       " 'subdivision_type': 492,\n",
       " 'among': 493,\n",
       " 've': 494,\n",
       " 'preserved': 495,\n",
       " 'james': 496,\n",
       " 'open': 497,\n",
       " 'force': 498,\n",
       " 'position': 499,\n",
       " 'head': 500,\n",
       " 'director': 501,\n",
       " 'father': 502,\n",
       " 'track': 503,\n",
       " 'http': 504,\n",
       " 'canada': 505,\n",
       " 'never': 506,\n",
       " 'australian': 507,\n",
       " 'id': 508,\n",
       " 'george': 509,\n",
       " 'org/w/index': 510,\n",
       " 'jpg': 511,\n",
       " 'level': 512,\n",
       " 'late': 513,\n",
       " 'summer': 514,\n",
       " 'society': 515,\n",
       " 'moved': 516,\n",
       " 'office': 517,\n",
       " 'period': 518,\n",
       " 'championship': 519,\n",
       " 'round': 520,\n",
       " 'story': 521,\n",
       " 'songs': 522,\n",
       " 'various': 523,\n",
       " 'file': 524,\n",
       " 'days': 525,\n",
       " 'land': 526,\n",
       " 'business': 527,\n",
       " 'tv': 528,\n",
       " 'subdivision_name': 529,\n",
       " 'reason': 530,\n",
       " 'america': 531,\n",
       " 'million': 532,\n",
       " 'european': 533,\n",
       " 'term': 534,\n",
       " 'al': 535,\n",
       " 'six': 536,\n",
       " 'uk': 537,\n",
       " 'post': 538,\n",
       " 'why': 539,\n",
       " 'produced': 540,\n",
       " 'making': 541,\n",
       " 'subject': 542,\n",
       " 'young': 543,\n",
       " 'total': 544,\n",
       " 'david': 545,\n",
       " 'science': 546,\n",
       " 'related': 547,\n",
       " 'rock': 548,\n",
       " 'archived': 549,\n",
       " 'railway': 550,\n",
       " 'become': 551,\n",
       " 'led': 552,\n",
       " 'students': 553,\n",
       " 'started': 554,\n",
       " 'news': 555,\n",
       " 'described': 556,\n",
       " '//www': 557,\n",
       " 'role': 558,\n",
       " 'election': 559,\n",
       " 'albums': 560,\n",
       " 'present': 561,\n",
       " 'indian': 562,\n",
       " 'kingdom': 563,\n",
       " 'books': 564,\n",
       " 'important': 565,\n",
       " 'northern': 566,\n",
       " 'love': 567,\n",
       " 'run': 568,\n",
       " 'canadian': 569,\n",
       " 'press': 570,\n",
       " 'rather': 571,\n",
       " 'k': 572,\n",
       " 'type': 573,\n",
       " 'act': 574,\n",
       " 'editor': 575,\n",
       " 'came': 576,\n",
       " 'schools': 577,\n",
       " 'program': 578,\n",
       " 'once': 579,\n",
       " 'issue': 580,\n",
       " 'social': 581,\n",
       " 'germany': 582,\n",
       " 'production': 583,\n",
       " 'male': 584,\n",
       " 'might': 585,\n",
       " 'awards': 586,\n",
       " 'points': 587,\n",
       " 'similar': 588,\n",
       " 'professional': 589,\n",
       " 'say': 590,\n",
       " 'background': 591,\n",
       " 'enough': 592,\n",
       " 'lead': 593,\n",
       " 'either': 594,\n",
       " 'common': 595,\n",
       " 'overlap': 596,\n",
       " 'data': 597,\n",
       " 'color': 598,\n",
       " 'better': 599,\n",
       " '•': 600,\n",
       " 'person': 601,\n",
       " 'services': 602,\n",
       " 'bgcolor': 603,\n",
       " 'museum': 604,\n",
       " 'battle': 605,\n",
       " 'went': 606,\n",
       " 'sports': 607,\n",
       " 'already': 608,\n",
       " 'currently': 609,\n",
       " 'hall': 610,\n",
       " 'buildings': 611,\n",
       " 'historic': 612,\n",
       " 'date': 613,\n",
       " 'deleted': 614,\n",
       " 'considered': 615,\n",
       " 'change': 616,\n",
       " 'location': 617,\n",
       " 'seems': 618,\n",
       " 'must': 619,\n",
       " 'yes': 620,\n",
       " 'our': 621,\n",
       " 'southern': 622,\n",
       " 'least': 623,\n",
       " 'lost': 624,\n",
       " 'something': 625,\n",
       " 'review': 626,\n",
       " 'together': 627,\n",
       " 'robert': 628,\n",
       " 'fact': 629,\n",
       " 'less': 630,\n",
       " 'japanese': 631,\n",
       " 'groups': 632,\n",
       " 'content': 633,\n",
       " 'birth_place': 634,\n",
       " 'involved': 635,\n",
       " 'isbn': 636,\n",
       " 'board': 637,\n",
       " 'japan': 638,\n",
       " 'control': 639,\n",
       " 'policy': 640,\n",
       " 'modern': 641,\n",
       " 'human': 642,\n",
       " 'half': 643,\n",
       " 'design': 644,\n",
       " 'event': 645,\n",
       " 'events': 646,\n",
       " 'available': 647,\n",
       " 'done': 648,\n",
       " 'washington': 649,\n",
       " 'real': 650,\n",
       " 'start': 651,\n",
       " 'personal': 652,\n",
       " 'action': 653,\n",
       " 'space': 654,\n",
       " 'areas': 655,\n",
       " 'doesn': 656,\n",
       " 'notability': 657,\n",
       " 'star': 658,\n",
       " 'really': 659,\n",
       " 'china': 660,\n",
       " 'possible': 661,\n",
       " 'paul': 662,\n",
       " 'working': 663,\n",
       " 'taken': 664,\n",
       " 'far': 665,\n",
       " 'going': 666,\n",
       " 'minister': 667,\n",
       " 'lake': 668,\n",
       " 'reported': 669,\n",
       " 'popular': 670,\n",
       " 'married': 671,\n",
       " 'founded': 672,\n",
       " 'europe': 673,\n",
       " 'author': 674,\n",
       " 'away': 675,\n",
       " 'independent': 676,\n",
       " 'process': 677,\n",
       " 'teams': 678,\n",
       " 'character': 679,\n",
       " 'low': 680,\n",
       " 'michael': 681,\n",
       " 'pages': 682,\n",
       " 'light': 683,\n",
       " 'big': 684,\n",
       " 'seen': 685,\n",
       " 'release': 686,\n",
       " 'want': 687,\n",
       " 'episode': 688,\n",
       " 'wrote': 689,\n",
       " 'republic': 690,\n",
       " 'thomas': 691,\n",
       " 'companies': 692,\n",
       " 'via': 693,\n",
       " 'russian': 694,\n",
       " 'thanks': 695,\n",
       " 'put': 696,\n",
       " 'race': 697,\n",
       " 'worked': 698,\n",
       " 'route': 699,\n",
       " 'recorded': 700,\n",
       " 'someone': 701,\n",
       " 'civil': 702,\n",
       " 'police': 703,\n",
       " 'charles': 704,\n",
       " 'listed': 705,\n",
       " 'users': 706,\n",
       " 'template': 707,\n",
       " 'instead': 708,\n",
       " 'eastern': 709,\n",
       " 'body': 710,\n",
       " 'question': 711,\n",
       " 'italian': 712,\n",
       " 'featured': 713,\n",
       " 'week': 714,\n",
       " 'editors': 715,\n",
       " 'texas': 716,\n",
       " 'chief': 717,\n",
       " 'close': 718,\n",
       " 'himself': 719,\n",
       " 'upon': 720,\n",
       " 'match': 721,\n",
       " 'q': 722,\n",
       " 'roman': 723,\n",
       " 'come': 724,\n",
       " 'opened': 725,\n",
       " 'tour': 726,\n",
       " 'sea': 727,\n",
       " 'actually': 728,\n",
       " 'cross': 729,\n",
       " 'playing': 730,\n",
       " 'health': 731,\n",
       " 'institute': 732,\n",
       " 'caps': 733,\n",
       " 'forces': 734,\n",
       " 'green': 735,\n",
       " 'rights': 736,\n",
       " 'evidence': 737,\n",
       " 'originally': 738,\n",
       " 'aircraft': 739,\n",
       " 'arts': 740,\n",
       " 'range': 741,\n",
       " 'probably': 742,\n",
       " 'consensus': 743,\n",
       " 'bar': 744,\n",
       " 'problem': 745,\n",
       " 'look': 746,\n",
       " 'issues': 747,\n",
       " 'alumni': 748,\n",
       " 'average': 749,\n",
       " 'network': 750,\n",
       " 'win': 751,\n",
       " 'shows': 752,\n",
       " 'wife': 753,\n",
       " 'returned': 754,\n",
       " 'night': 755,\n",
       " 'magazine': 756,\n",
       " 'centre': 757,\n",
       " 'joined': 758,\n",
       " 'usually': 759,\n",
       " 'middle': 760,\n",
       " 'completed': 761,\n",
       " 'elected': 762,\n",
       " 'significant': 763,\n",
       " 'african': 764,\n",
       " 'able': 765,\n",
       " 'google': 766,\n",
       " 'stage': 767,\n",
       " 'addition': 768,\n",
       " 'ireland': 769,\n",
       " 'today': 770,\n",
       " 'academy': 771,\n",
       " 'saint': 772,\n",
       " 'self': 773,\n",
       " 'itself': 774,\n",
       " 'continued': 775,\n",
       " 'stations': 776,\n",
       " 'mother': 777,\n",
       " 'appeared': 778,\n",
       " 'africa': 779,\n",
       " 'culture': 780,\n",
       " 'spanish': 781,\n",
       " 'grand': 782,\n",
       " 'committee': 783,\n",
       " 'things': 784,\n",
       " 'fire': 785,\n",
       " 'changed': 786,\n",
       " 'gold': 787,\n",
       " 'female': 788,\n",
       " 'course': 789,\n",
       " 'directed': 790,\n",
       " 'months': 791,\n",
       " 'whether': 792,\n",
       " 'chinese': 793,\n",
       " 'previous': 794,\n",
       " 'developed': 795,\n",
       " 'size': 796,\n",
       " 'mentioned': 797,\n",
       " 'add': 798,\n",
       " 'festival': 799,\n",
       " 'peter': 800,\n",
       " 'basketball': 801,\n",
       " 'across': 802,\n",
       " 'move': 803,\n",
       " 'performance': 804,\n",
       " 'standard': 805,\n",
       " 'means': 806,\n",
       " 'give': 807,\n",
       " 'training': 808,\n",
       " 'artist': 809,\n",
       " 'word': 810,\n",
       " 'blue': 811,\n",
       " 'primary': 812,\n",
       " 'announced': 813,\n",
       " 'value': 814,\n",
       " 'christian': 815,\n",
       " 'private': 816,\n",
       " 'catholic': 817,\n",
       " 'artists': 818,\n",
       " 'includes': 819,\n",
       " 'view': 820,\n",
       " 'thus': 821,\n",
       " 'almost': 822,\n",
       " 'baseball': 823,\n",
       " 'seven': 824,\n",
       " 'appears': 825,\n",
       " 'ever': 826,\n",
       " 'provide': 827,\n",
       " 'technology': 828,\n",
       " 'olympics': 829,\n",
       " 'future': 830,\n",
       " 'formed': 831,\n",
       " 'census': 832,\n",
       " 'nd': 833,\n",
       " 'images': 834,\n",
       " 'los': 835,\n",
       " 'results': 836,\n",
       " 'return': 837,\n",
       " 'quality': 838,\n",
       " 'construction': 839,\n",
       " 'zealand': 840,\n",
       " 'front': 841,\n",
       " 'cover': 842,\n",
       " 'model': 843,\n",
       " 'despite': 844,\n",
       " 'read': 845,\n",
       " 'material': 846,\n",
       " 'strong': 847,\n",
       " 'coach': 848,\n",
       " 'henry': 849,\n",
       " 'footballers': 850,\n",
       " 'mark': 851,\n",
       " 'rev': 852,\n",
       " 'organization': 853,\n",
       " 'studies': 854,\n",
       " 'federal': 855,\n",
       " 'richard': 856,\n",
       " 'html': 857,\n",
       " 'virginia': 858,\n",
       " 'car': 859,\n",
       " 'attack': 860,\n",
       " 'conference': 861,\n",
       " 'outside': 862,\n",
       " 'study': 863,\n",
       " 'brother': 864,\n",
       " 'names': 865,\n",
       " 'throughout': 866,\n",
       " 'writer': 867,\n",
       " 'characters': 868,\n",
       " 'musical': 869,\n",
       " 'nothing': 870,\n",
       " 'border': 871,\n",
       " 'medical': 872,\n",
       " 'countries': 873,\n",
       " 'past': 874,\n",
       " 'writing': 875,\n",
       " 'makes': 876,\n",
       " 'interest': 877,\n",
       " 'provided': 878,\n",
       " 'killed': 879,\n",
       " 'medal': 880,\n",
       " 'signed': 881,\n",
       " 'dr': 882,\n",
       " 'largest': 883,\n",
       " 'label': 884,\n",
       " 'fair': 885,\n",
       " 'search': 886,\n",
       " 'bay': 887,\n",
       " 'reference': 888,\n",
       " 'especially': 889,\n",
       " 'refer': 890,\n",
       " 'removed': 891,\n",
       " 'library': 892,\n",
       " 'eventually': 893,\n",
       " 'management': 894,\n",
       " 'references': 895,\n",
       " 'features': 896,\n",
       " 'navy': 897,\n",
       " 'guitar': 898,\n",
       " 'hill': 899,\n",
       " 'sure': 900,\n",
       " 'historical': 901,\n",
       " 'lower': 902,\n",
       " 'daughter': 903,\n",
       " 'appointed': 904,\n",
       " 'reading': 905,\n",
       " 'yet': 906,\n",
       " 'systems': 907,\n",
       " 'debut': 908,\n",
       " 'movement': 909,\n",
       " 'fc': 910,\n",
       " 'specific': 911,\n",
       " 'always': 912,\n",
       " 'actor': 913,\n",
       " 'natural': 914,\n",
       " 'clear': 915,\n",
       " 'coast': 916,\n",
       " 'let': 917,\n",
       " 'got': 918,\n",
       " 'chicago': 919,\n",
       " 'championships': 920,\n",
       " 'll': 921,\n",
       " 'pennsylvania': 922,\n",
       " 'ten': 923,\n",
       " 'performed': 924,\n",
       " 'individual': 925,\n",
       " 'designed': 926,\n",
       " 'rule': 927,\n",
       " 'etc': 928,\n",
       " 'lists': 929,\n",
       " 'paris': 930,\n",
       " 'thought': 931,\n",
       " 'brown': 932,\n",
       " 'hand': 933,\n",
       " 'needs': 934,\n",
       " 'reliable': 935,\n",
       " 'smith': 936,\n",
       " 'generally': 937,\n",
       " 'base': 938,\n",
       " 'sometimes': 939,\n",
       " 'florida': 940,\n",
       " 'capital': 941,\n",
       " 'valley': 942,\n",
       " 'bank': 943,\n",
       " 'gave': 944,\n",
       " 'ground': 945,\n",
       " 'reached': 946,\n",
       " 'italy': 947,\n",
       " 'energy': 948,\n",
       " 'believe': 949,\n",
       " 'leader': 950,\n",
       " 'active': 951,\n",
       " 'online': 952,\n",
       " 'block': 953,\n",
       " 'bridge': 954,\n",
       " 'families': 955,\n",
       " 'changes': 956,\n",
       " 'y': 957,\n",
       " 'followed': 958,\n",
       " 'industry': 959,\n",
       " 'collection': 960,\n",
       " 'request': 961,\n",
       " 'soon': 962,\n",
       " 'leading': 963,\n",
       " 'olympic': 964,\n",
       " 'sold': 965,\n",
       " 'writers': 966,\n",
       " 'professor': 967,\n",
       " 'studio': 968,\n",
       " 'mexico': 969,\n",
       " 'competition': 970,\n",
       " 'campaign': 971,\n",
       " 'org': 972,\n",
       " 'theatre': 973,\n",
       " 'anything': 974,\n",
       " 'particular': 975,\n",
       " 'empire': 976,\n",
       " 'length': 977,\n",
       " 'islands': 978,\n",
       " 'singer': 979,\n",
       " 'create': 980,\n",
       " 'redirect': 981,\n",
       " 'additional': 982,\n",
       " 'soviet': 983,\n",
       " 'market': 984,\n",
       " 'words': 985,\n",
       " 'producer': 986,\n",
       " 'notes': 987,\n",
       " 'hockey': 988,\n",
       " 'novel': 989,\n",
       " 'code': 990,\n",
       " 'referee': 991,\n",
       " 'fourth': 992,\n",
       " 'sport': 993,\n",
       " 'van': 994,\n",
       " 'mary': 995,\n",
       " 'airport': 996,\n",
       " 'sound': 997,\n",
       " 'status': 998,\n",
       " 'irish': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use needed word embeddings, do this to save RAM\n",
    "# Build vocab on training data\n",
    "train_vocab = {'PAD': 0}  # special padding symbol\n",
    "selected_word_embeddings = [np.zeros(word_embeddings.shape[1])]  # zero vector for PAD symbol\n",
    "for tokens in train_tokens:\n",
    "    for token in tokens:\n",
    "        if not token in train_vocab:\n",
    "            if token in vocab:\n",
    "                train_vocab[token] = max(train_vocab.values()) + 1\n",
    "                selected_word_embeddings.append(word_embeddings[vocab[token]])\n",
    "\n",
    "selected_word_embeddings = np.array(selected_word_embeddings)\n",
    "del word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok2int(tokens_list, vocab):\n",
    "    \"\"\"Replaces tokens with their assigned IDs\"\"\"\n",
    "    token_ints = list()\n",
    "    for tokens in tokens_list:\n",
    "        token_ints.append([vocab[tok] for tok in tokens if tok in vocab])\n",
    "    return token_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max(len(tokens) for tokens in train_tokens)\n",
    "train_ints = tok2int(train_tokens, train_vocab)\n",
    "# Make all texts the same length, pad with zeroes\n",
    "# train_ints_padded = tf.keras.utils.pad_sequences(train_ints, maxlen=maxlen)\n",
    "train_ints_padded = tf.keras.preprocessing.sequence.pad_sequences(train_ints, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronales Netz mit vortrainierten word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3350, 300)         6969000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 300)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               154112    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,125,677\n",
      "Trainable params: 156,677\n",
      "Non-trainable params: 6,969,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model: Try changing the layers and their sizes\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(train_vocab), # Number of tokens in the dicitonary\n",
    "                                    mask_zero=True,  # ignore padding symbol\n",
    "                                    input_length=maxlen,  # max text length\n",
    "                                    embeddings_initializer=tf.keras.initializers.Constant(selected_word_embeddings),  # initialize the embeddings with the pretrained ones\n",
    "                                    trainable=False,  # we're not updating the pre-trained word embeddings\n",
    "                                    output_dim=300)  # dimensions of the word embeddings\n",
    "         )\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())  # Average the word embeddings\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))  # \"Hidden\" layer\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(256, activation='relu'))  # \"Hidden\" layer\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu'))  # \"Hidden\" layer\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))  # Final classification layer\n",
    "model.compile(optimizer='adam', loss='CategoricalCrossentropy')\n",
    "print(model.summary())\n",
    "save_NN_summary(base_dir, foldername, model, \"/NN_Summary_pretrained_wordemebddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51/51 [==============================] - 5s 81ms/step - loss: 1.5069 - val_loss: 1.3909\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 1.2238 - val_loss: 1.0889\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 0.9005 - val_loss: 0.7648\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 0.6427 - val_loss: 0.5641\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.4821 - val_loss: 0.4480\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.3775 - val_loss: 0.3640\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 0.3208 - val_loss: 0.3103\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.2773 - val_loss: 0.2774\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 4s 74ms/step - loss: 0.2530 - val_loss: 0.2735\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 0.2295 - val_loss: 0.2388\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.2138 - val_loss: 0.2312\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 0.1963 - val_loss: 0.2279\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.1816 - val_loss: 0.2144\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 0.1698 - val_loss: 0.1910\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.1608 - val_loss: 0.1871\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 4s 73ms/step - loss: 0.1544 - val_loss: 0.2034\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 4s 72ms/step - loss: 0.1516 - val_loss: 0.1925\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 4s 78ms/step - loss: 0.1523 - val_loss: 0.1724\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 0.1317 - val_loss: 0.1631\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 0.1293 - val_loss: 0.1642\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 4s 77ms/step - loss: 0.1277 - val_loss: 0.1690\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 4s 76ms/step - loss: 0.1230 - val_loss: 0.1720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8df29ddc0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(train_ints_padded, train_labels, epochs=30, verbose=1, validation_split=0.1, callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.89      0.97      0.93       111\n",
      "entertainment       0.99      0.96      0.97        74\n",
      "     politics       0.99      0.88      0.93        86\n",
      "        sport       1.00      0.98      0.99       108\n",
      "         tech       0.88      0.91      0.90        66\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.94      0.94       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict & Evaluate\n",
    "test_tokens = tokenize(X_test_bbc.tolist())\n",
    "test_ints = tok2int(test_tokens, train_vocab)\n",
    "# Make all texts the same length, pad with zeroes\n",
    "test_ints_padded = tf.keras.preprocessing.sequence.pad_sequences(test_ints, maxlen=maxlen)\n",
    "predicted_labels_pretrained_int = model.predict(test_ints_padded)\n",
    "predicted_labels_pretrained = ohe.inverse_transform(predicted_labels_pretrained_int)  # Map predicted scores back to labels\n",
    "predicted_labels_pretrained = [labels[0] for labels in predicted_labels_pretrained]\n",
    "print(classification_report(y_test_bbc, predicted_labels_pretrained))\n",
    "save_NN_result(base_dir, foldername, str(classification_report(y_test_bbc, predicted_labels_pretrained, digits = 4)), \"/test_prediction_NN_result_pretrained_wordembeddings\")\n",
    "save_wrong_predictions(y_test_bbc, predicted_labels_pretrained, base_dir, foldername, '/pretrained_wordembeddings_wrong_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0   1   0   2]\n",
      " [  0  71   0   0   3]\n",
      " [  7   0  76   0   3]\n",
      " [  1   1   0 106   0]\n",
      " [  6   0   0   0  60]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_bbc,predicted_labels_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronales Netz aber die embeddings von scratch lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1687, 300)         6969000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 300)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               154112    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,125,677\n",
      "Trainable params: 7,125,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Same architecture but learn the embeddings from scratch\n",
    "# del model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(train_vocab), output_dim=300, mask_zero=True, input_length=maxlen_clean))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())  # Average the word embeddings\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(256, activation='relu'))  # \"Hidden\" layer\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu'))  # \"Hidden\" layer\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='CategoricalCrossentropy')\n",
    "print(model.summary())\n",
    "save_NN_summary(base_dir, foldername, model, \"/NN_Summary_train_wordembeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "51/51 [==============================] - 13s 230ms/step - loss: 1.3021 - val_loss: 0.5894\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 12s 227ms/step - loss: 0.1600 - val_loss: 0.0853\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 12s 230ms/step - loss: 0.0148 - val_loss: 0.0578\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 0.0050 - val_loss: 0.0552\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 11s 225ms/step - loss: 0.0029 - val_loss: 0.0509\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 11s 225ms/step - loss: 0.0019 - val_loss: 0.0489\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 11s 225ms/step - loss: 0.0013 - val_loss: 0.0484\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 12s 228ms/step - loss: 0.0010 - val_loss: 0.0474\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 12s 226ms/step - loss: 7.7456e-04 - val_loss: 0.0481\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 12s 227ms/step - loss: 6.3528e-04 - val_loss: 0.0460\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 11s 226ms/step - loss: 5.2589e-04 - val_loss: 0.0464\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 4.3343e-04 - val_loss: 0.0453\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 12s 228ms/step - loss: 3.5551e-04 - val_loss: 0.0452\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 12s 235ms/step - loss: 3.0791e-04 - val_loss: 0.0454\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 12s 227ms/step - loss: 2.7394e-04 - val_loss: 0.0454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc0a503fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(train_ints_padded_clean, train_labels_clean, epochs=20, verbose=1, validation_split=0.1 ,callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       111\n",
      "           1       1.00      0.97      0.99        74\n",
      "           2       0.95      0.98      0.97        86\n",
      "           3       1.00      0.98      0.99       108\n",
      "           4       0.94      0.97      0.96        66\n",
      "\n",
      "    accuracy                           0.97       445\n",
      "   macro avg       0.97      0.97      0.97       445\n",
      "weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict & Evaluate\n",
    "# test_tokens = tokenize(X_test_bbc.tolist())\n",
    "test_tokens = tokenize(X_test.tolist())\n",
    "test_ints = tok2int(test_tokens, train_vocab)\n",
    "# Make all texts the same length, pad with zeroes\n",
    "test_ints_padded = tf.keras.preprocessing.sequence.pad_sequences(test_ints, maxlen=maxlen_clean)\n",
    "predicted_labels_pretrained_int = model.predict(test_ints_padded)\n",
    "predicted_labels_pretrained = ohe.inverse_transform(predicted_labels_pretrained_int)  # Map predicted scores back to labels\n",
    "predicted_labels_pretrained = [labels[0] for labels in predicted_labels_pretrained]\n",
    "# print(classification_report(y_test_bbc, predicted_labels_pretrained))\n",
    "# save_NN_result(base_dir, foldername, str(classification_report(y_test_bbc, predicted_labels_pretrained, digits = 4)), \"/test_prediction_NN_result_train_wordembeddings\")\n",
    "# save_wrong_predictions(y_test_bbc, predicted_labels_pretrained, base_dir, foldername, '/train_wordembeddings_wrong_pred')\n",
    "print(classification_report(y_test, predicted_labels_pretrained))\n",
    "save_NN_result(base_dir, foldername, str(classification_report(y_test, predicted_labels_pretrained, digits = 4)), \"/test_prediction_NN_result_train_wordembeddings\")\n",
    "save_wrong_predictions(y_test, predicted_labels_pretrained, base_dir, foldername, '/train_wordembeddings_wrong_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   0   3   0   2]\n",
      " [  0  72   0   0   2]\n",
      " [  2   0  84   0   0]\n",
      " [  1   0   1 106   0]\n",
      " [  2   0   0   0  64]]\n"
     ]
    }
   ],
   "source": [
    "# print(confusion_matrix(y_test_bbc,predicted_labels_pretrained))\n",
    "print(confusion_matrix(y_test,predicted_labels_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronales Netz mit vortrainierten word embeddings aber weiter trainiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 3350, 300)         6969000   \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 300)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               154112    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,125,677\n",
      "Trainable params: 7,125,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(train_vocab), \n",
    "                                    mask_zero=True, input_length=maxlen, \n",
    "                                    embeddings_initializer=tf.keras.initializers.Constant(selected_word_embeddings),\n",
    "                                    trainable=True,\n",
    "                                    output_dim=300)\n",
    "         )\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='CategoricalCrossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51/51 [==============================] - 11s 208ms/step - loss: 1.3962 - val_loss: 1.0136\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 10s 204ms/step - loss: 0.5275 - val_loss: 0.2788\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 10s 203ms/step - loss: 0.1183 - val_loss: 0.1200\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 10s 203ms/step - loss: 0.0431 - val_loss: 0.0927\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 10s 203ms/step - loss: 0.0203 - val_loss: 0.0770\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 15s 297ms/step - loss: 0.0115 - val_loss: 0.0714\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 16s 313ms/step - loss: 0.0065 - val_loss: 0.0617\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 21s 390ms/step - loss: 0.0045 - val_loss: 0.0617\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 15s 301ms/step - loss: 0.0034 - val_loss: 0.0600\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 15s 299ms/step - loss: 0.0025 - val_loss: 0.0584\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 15s 300ms/step - loss: 0.0020 - val_loss: 0.0571\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 15s 303ms/step - loss: 0.0016 - val_loss: 0.0561\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 15s 302ms/step - loss: 0.0013 - val_loss: 0.0551\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 16s 306ms/step - loss: 0.0011 - val_loss: 0.0553\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 16s 306ms/step - loss: 9.3217e-04 - val_loss: 0.0551\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 15s 303ms/step - loss: 8.1500e-04 - val_loss: 0.0543\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 15s 304ms/step - loss: 6.9099e-04 - val_loss: 0.0541\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 15s 303ms/step - loss: 5.8983e-04 - val_loss: 0.0532\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 16s 305ms/step - loss: 5.3207e-04 - val_loss: 0.0550\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 16s 304ms/step - loss: 4.9937e-04 - val_loss: 0.0517\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 16s 317ms/step - loss: 4.3713e-04 - val_loss: 0.0516\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 16s 313ms/step - loss: 3.5673e-04 - val_loss: 0.0522\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 16s 317ms/step - loss: 3.5578e-04 - val_loss: 0.0521\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 16s 320ms/step - loss: 3.3832e-04 - val_loss: 0.0518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8c38207c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(train_ints_padded, train_labels, epochs=30, verbose=1, validation_split=0.1, callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.96      0.96       111\n",
      "entertainment       1.00      0.99      0.99        74\n",
      "     politics       0.98      0.97      0.97        86\n",
      "        sport       1.00      0.99      1.00       108\n",
      "         tech       0.96      0.98      0.97        66\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict & Evaluate\n",
    "test_tokens = tokenize(X_test_bbc.tolist())\n",
    "test_ints = tok2int(test_tokens, train_vocab)\n",
    "# Make all texts the same length, pad with zeroes\n",
    "test_ints_padded = tf.keras.preprocessing.sequence.pad_sequences(test_ints, maxlen=maxlen)\n",
    "predicted_labels_pretrained_int = model.predict(test_ints_padded)\n",
    "predicted_labels_pretrained = ohe.inverse_transform(predicted_labels_pretrained_int)  # Map predicted scores back to labels\n",
    "predicted_labels_pretrained = [labels[0] for labels in predicted_labels_pretrained]\n",
    "print(classification_report(y_test_bbc, predicted_labels_pretrained))\n",
    "save_NN_result(base_dir, foldername, str(classification_report(y_test_bbc, predicted_labels_pretrained, digits = 4)), \"/test_prediction_NN_result_pretrained_wordembeddings_further_trained\")\n",
    "save_wrong_predictions(y_test_bbc, predicted_labels_pretrained, base_dir, foldername, '/pretrained_wordembeddings_further_trained_wrong_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   0   2   0   2]\n",
      " [  0  73   0   0   1]\n",
      " [  3   0  83   0   0]\n",
      " [  1   0   0 107   0]\n",
      " [  1   0   0   0  65]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_bbc,predicted_labels_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26812/1705887190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__label__'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mto_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_tokens_clean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26812/1705887190.py\u001b[0m in \u001b[0;36mto_disk\u001b[1;34m(texts, labels, outfile)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__label__'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mto_disk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_tokens_clean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# We need to write the files to disk\n",
    "def to_disk(texts: list[str], labels: list[str], outfile: str):\n",
    "    with open(outfile, 'w') as f:\n",
    "        for label, text in zip(labels, texts):\n",
    "            f.write('__label__' + label + ' ' + text.lower() + '\\n')\n",
    "\n",
    "to_disk([' '.join(tokens) for tokens in train_tokens_clean], y_train.tolist(), 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "\n",
    "model = fasttext.train_supervised(input=\"train.txt\", epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      0.95      0.94       111\n",
      "entertainment       0.90      0.86      0.88        74\n",
      "     politics       0.91      0.92      0.91        86\n",
      "        sport       0.97      0.95      0.96       108\n",
      "         tech       0.88      0.88      0.88        66\n",
      "\n",
      "     accuracy                           0.92       445\n",
      "    macro avg       0.92      0.91      0.92       445\n",
      " weighted avg       0.92      0.92      0.92       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_fasttext_orig = [model.predict(' '.join(tokens)) for tokens in test_tokens]\n",
    "predictions_fasttext = [pred[0][0].replace('__label__', '') for pred in predictions_fasttext_orig]\n",
    "print(classification_report(y_test_bbc, predictions_fasttext))\n",
    "save_NN_result(base_dir, foldername, str(classification_report(y_test_bbc, predictions_fasttext, digits = 4)), \"/test_prediction_NN_fasttext\")\n",
    "save_wrong_predictions(y_test_bbc, predictions_fasttext, base_dir, foldername, '/fasttext_wrong_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   1   1   0   3]\n",
      " [  2  64   5   1   2]\n",
      " [  0   3  79   1   3]\n",
      " [  0   3   2 103   0]\n",
      " [  7   0   0   1  58]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_bbc,predictions_fasttext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong Predictions All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername1 = \"Full_text_cleaning_Yes_HT_adjustedVectorizer_FINAL\"\n",
    "foldername2 = \"Full_text_cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = pd.read_pickle(base_dir + foldername1 + \"/LinearSVC_wrong_pred_TFIDF.pickle\") \n",
    "list2 = pd.read_pickle(base_dir + foldername1 + \"/RandomForest_wrong_pred_TFIDF.pickle\") \n",
    "list3 = pd.read_pickle(base_dir + foldername1 + \"/LogisicRegression_wrong_pred_TFIDF.pickle\") \n",
    "list4 = pd.read_pickle(base_dir + foldername1 + \"/MultinomialNB_wrong_pred_TFIDF.pickle\") \n",
    "list5 = pd.read_pickle(base_dir + foldername2 + \"/pretrained_wordembeddings_further_trained_wrong_pred.pickle\") \n",
    "list6 = pd.read_pickle(base_dir + foldername2 + \"/train_wordembeddings_wrong_pred.pickle\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_business(list):\n",
    "    business_list = []\n",
    "    for i in range(0,len(list)):\n",
    "        \n",
    "        if bbc_df.iloc[[list[i]]]['label'].values[0] == 'business':\n",
    "            business_list.append(list[i])\n",
    "        \n",
    "    return business_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[list1[1]]]['label'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = wrong_business(list1)\n",
    "rf = wrong_business(list2)\n",
    "logreg = wrong_business(list3)\n",
    "mnb = wrong_business(list4)\n",
    "further = wrong_business(list5)\n",
    "scratch = wrong_business(list6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Algo vergleich\n",
    "def comparelists2(a,b,c):\n",
    "    z = [x for x in b\n",
    "         if x in a and x in c] #list comprehension\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[446, 132, 503, 206, 254, 253, 486]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparelists2(lsvc,logreg,mnb)\n",
    "# Alle Sklearn Modelle machen den gleichen Fehler (lsvc, logreg, mnb)\n",
    "# [446, 132, 503, 206, 254, 253, 486]\n",
    "\n",
    "# Nur in lsvc\n",
    "# [361, 251]\n",
    "\n",
    "# Nur in MNB\n",
    "# [251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[446, 132, 503, 206, 251, 254, 253, 486]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparelists3(a,b):\n",
    "    z = [x for x in b\n",
    "         if x in a] #list comprehension\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[446, 132, 254, 253]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparelists3(further, scratch)\n",
    "# Beide Wordembeddings machen die gleichen Fehler\n",
    "# [446, 132, 254, 253]\n",
    "\n",
    "# Diese sind auch in den Sklearn Modellen falsch \n",
    "\n",
    "# Nur in Sklearn Modellen falsch\n",
    "# [503, 206, 486]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>./bbc/business</td>\n",
       "      <td>133.txt</td>\n",
       "      <td>Salary scandal in Cameroon</td>\n",
       "      <td>Cameroon says widespread corruption in its f...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>cameroon say widespread corrupt financ ministr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          directory     file                       title  \\\n",
       "132  ./bbc/business  133.txt  Salary scandal in Cameroon   \n",
       "\n",
       "                                                  text     label  label_num  \\\n",
       "132    Cameroon says widespread corruption in its f...  business          0   \n",
       "\n",
       "                                            text_clean  \n",
       "132  cameroon say widespread corrupt financ ministr...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[132]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Cameroon says widespread corruption in its finance ministry has cost it 1bn CFA francs ($2m; £1m) a month.  About 500 officials are accused of either awarding themselves extra money or claiming salaries for \"non-existent\" workers. Prime Minister Ephraim Inoni, who vowed to tackle corruption when he came to office last year, said those found guilty would face tough punishments. The scam is believed to have begun in 1994.  The prime minister\\'s office said the alleged fraud was uncovered during an investigation into the payroll at the ministry. In certain cases, staff are said to have lied about their rank and delayed their retirement in order to boost their earnings. The prime minister\\'s office said auditors had found \"irregularities in the career structure of certain civil servants\". It added that the staff in question \"appear to have received unearned salaries, boosting the payroll\".  Fidelis Nanga, a journalist based in the Cameroon capital Yaounde, said the government was considering taking criminal action against those found guilty and forcing them to repay any money owed. \"The prime minister has given instructions for exemplary penalties to be meted out against the accused and their accomplices if found guilty,\" he told the BBC\\'s Network Africa programme.  Mr Inoni launched an anti-corruption drive in December after foreign investors criticised a lack of transparency in the country\\'s public finances. In one initiative designed to improve efficiency, civil servants who arrived late for work were locked out of their offices. The government now intends to carry out an audit of payrolls at all other government ministries. In a report compiled by anti-corruption body Transparency International in 2003, graft was said to be \"pervasive\" in Cameroon.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.iloc[[132]]['text'][132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels2(index):\n",
    "    list1 = pd.read_pickle(base_dir + foldername1 + \"/LinearSVC_pred_labels.pickle\") \n",
    "    list2 = pd.read_pickle(base_dir + foldername1 + \"/RandomForest_pred_labels.pickle\") \n",
    "    list3 = pd.read_pickle(base_dir + foldername1 + \"/LogisicRegression_pred_labels.pickle\") \n",
    "    list4 = pd.read_pickle(base_dir + foldername1 + \"/MultinomialNB_pred_labels.pickle\") \n",
    "    # list5 = pd.read_pickle(base_dir + foldername2 + \"/MultinomialNB_pred_labels.pickle\") \n",
    "    # list6 = pd.read_pickle(base_dir + foldername2 + \"/MultinomialNB_pred_labels.pickle\") \n",
    "    print('True Value: ' + bbc_df.iloc[[wrong_pred_list[0]]]['label'])\n",
    "    return [('LinearSVC','Preditcted: ' + label_lookup_table[list1.loc[[index]][0][index]]), \n",
    "        ('RandomForest','Preditcted: ' +  label_lookup_table[list2.loc[[index]][0][index]]), \n",
    "        ('LogisticRegression','Preditcted: ' +  label_lookup_table[list3.loc[[index]][0][index]]), \n",
    "        ('MultinomialNB','Preditcted: ' +  label_lookup_table[list4.loc[[index]][0][index]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503    True Value: business\n",
      "Name: label, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LinearSVC', 'Preditcted: politics'), ('RandomForest', 'Preditcted: politics'), ('LogisticRegression', 'Preditcted: politics'), ('MultinomialNB', 'Preditcted: politics')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels2(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bbc = y_test_bbc.drop('new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384     business\n",
       "1983        tech\n",
       "985     politics\n",
       "1386       sport\n",
       "1294    politics\n",
       "          ...   \n",
       "438     business\n",
       "299     business\n",
       "1285    politics\n",
       "1505       sport\n",
       "2035        tech\n",
       "Name: label, Length: 445, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_test_bbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = predicted_labels_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>business</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label      pred\n",
       "132  business  politics"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[132]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d18e30d5c6af1a1c6f183cb544530f3398c73ecbe9cf7db5c9ea8cf67386e9c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
